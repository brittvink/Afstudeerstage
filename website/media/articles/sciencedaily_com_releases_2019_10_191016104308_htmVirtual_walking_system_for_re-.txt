A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Walking is a natural and frequent action performed by healthy adults in everyday life. It involves various sensations such as vision, touch, hearing, and proprioception, as well as performing motor commands and actions. Therefore, it would represent a challenge to develop a virtual reality system capable of reproducing the walking sensation. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Recently, to address the above problem, a research team in Japan have developed a virtual walking system with focusing on vision and foot vibrations, because these modalities seem critical and a minimal set to induce walking sensations. The proposed recording system captures the walker's oscillating optic flow with a pair of stereo cameras, and records the timings of feet striking the ground using four microphones embedded in their shoes. The proposed system comprises a head-mounted display (HMD) and four vibrators attached to the heels and the forefeet. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Psychological experiments were conducted to test the virtual walking system. The captured first-person-view scenes with image oscillations caused by the walker's head motion and the foot vibrations at synchronized timings significantly induced the sensations of self-motion, walking, leg action, and telepresence. The synchronous presentation of visual oscillations and foot vibrations was critical for enhancing the virtual walking experience. These results confirm that tactile stimulation on the feet for footsteps is effective for enhancing virtual walking sensations. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Professor Michiteru Kitazaki, a perceptual psychologist at the Toyohashi University of Technology said, "We would like to develop the virtual reality system further, enabling people to walk on strange places such as the Moon or the ocean bottom, and possibly improving the quality of life of people who have walking disabilities. This research is the first step to achieving these goals. Accordingly, we aim to create the virtual sensation of walking using limited modalities, such as vision and tactile sensations. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Associate Professor Tomohiro Amemiya, a young virtual reality researcher whose research specializes in haptics at the University of Tokyo explained "Tactile sensation on the foot-sole can induce a pseudo-walking sensation. The present research demonstrated the psychological evidence for this. In addition, in our other paper published in "Psychological Science," we have found that a similar rhythmic pattern consisting of walking vibrations applied to the soles of the feet facilitated tactile processing when looming sounds were located near the body. The findings suggest that extension of the peripersonal space representation can be enabled by stimulating the soles in the absence of body action, which may automatically drive a motor programing in the brain for walking, leading to a change in spatial cognition around the body. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Professor Yasushi Ikei, a virtual reality expert researcher at Tokyo Metropolitan University said "During the set of related studies, we are developing a full-scale super-presence virtual re-experience system. For example, FiveStar VR (which won the best VR/AR technology award at ACM SIGGRAPH Asia 2018) represents vision, vestibular sense, proprioception, smells, air flow, sounds, and touch to re-experience the experiences of another person (https://youtu.be/mOS5JJBSZ3c). The re-experience system allows expanding our experiences and contributes to skill transfer and improving the quality of life for all people. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.In this way, the virtual walking system could expand our experience and improve the quality of life for people that may have future walking disabilities. A research team consisting of Professor Michiteru Kitazaki from the Toyohashi University of Technology, Associate Professor Tomohiro Amemiya from the University of Tokyo, and Professor Yasushi Ikei from Tokyo Metropolitan University have developed a virtual walking system. This system records a person walking, then re-plays it to another user through the oscillating optic flow and synchronous foot vibrations. Psychological experiments confirmed that the sensations of self-motion, walking, leg action, and telepresence provided by the oscillating visual flow combined with foot vibrations are stronger than with randomized-timing vibrations or without any vibrations. These results suggest that oscillating visual scenes and synchronous foot vibrations are effective for creating virtual walking sensations. The virtual walking system can reproduce experiences of walking to people who are a distance away, or who have a disability that could prevent them from walking in the future. This research has been published in the British open access journal "i-Perception" in 15th October 2019.Funding: This research was supported by the SCOPE program (141203019), Grant-in-Aid for Scientific Research (A) (18H04118), and Grant-in-Aid for Challenging Exploratory Research (16K12477) by MEXT Japan. 