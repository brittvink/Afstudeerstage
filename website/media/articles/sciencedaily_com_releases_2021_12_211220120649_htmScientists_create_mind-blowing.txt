Researchers say the new tool gives an unprecedented view of brain cell activity in a synapse -- a tiny space between two brain cells, where molecules and chemicals are passed back and forth. It was science fiction to be able to image nearly every synapse in the brain and watch a change in behavior," says Richard Huganir, Ph.D., Bloomberg Distinguished Professor of Neuroscience and Psychological and Brain Sciences at The Johns Hopkins University and director of the Department of Neuroscience at the Johns Hopkins University School of Medicine. A summary of the research was published online first Oct. 18 and in its final form Nov. 25 in the journal eLife. The researchers never thought they'd be able to see brain activity on such a massive scale. They say that before developing the tool, their ability to see brain cell activity was like looking up in the night sky with bare eyes and seeing billions of stars. "It's like we can see and track each of the stars at the same time" now, says Austin Graves, Ph.D., instructor of neuroscience at the Johns Hopkin University School of Medicine. The space between brain cells, or neurons, is incredibly tiny. It's less than a micron -- about a tenth of the width of a human hair. Within these junctions between neurons is a highway of passing molecules and proteins -- mainly sodium and calcium -- transferring from one neuron to the next. When neurotransmitters pass across a synapse and land on a neuron, they activate an AMPA glutamate receptor -- a protein in the neuron's outer covering. "These receptors are the functional machinery of language between neurons," says Graves. Huganir and other scientists have shown that synapses and the receptors embedded in them are key locations for learning in the brain. It's where memories are encoded, they say. To study how synapses operate, scientists customarily culture samples of brain cells in the laboratory to screen for increases or decreases in proteins made by the cells. They also examine subsets of neurons in various regions of the brain, but scientists had not previously been able to image synapses in the entire brain on this scale, say the researchers. For the research, the scientists genetically engineered mice by inserting the GRIA1 gene into the DNA, producing a green glowing tag on all AMPA glutamate proteins. When neurons amp up their signaling, they produce more AMPA glutamate proteins, and the green signal gets brighter. Since AMPA glutamate receptors are very common, the researchers were able to pinpoint nearly all excitatory neurons -- which are more likely to send signals to other neurons instead of block them -- in the mouse brain. Then, the researchers tweaked a whisker on each mouse and used high powered microscopes to track which synapses glowed green and the brightness of the signal. They found about 600,000 glowing synapses and indications that the brightness of the green signal corresponded to the strength of the AMPA glutamate receptor's response. Huganir says the new system generates mind-boggling amounts of data. So, the researchers worked with computational scientists in the Johns Hopkins Department of Biomedical Engineering to develop artificial intelligence and machine learning techniques to train and validate algorithms that automatically detect all of the glowing synapses and how they change over time with experience and learning. Their current work is a proof-of-principle study that shows the capabilities of this synaptic imaging tool, say the researchers. Other scientists have asked to use the genetically engineered mice in their studies. The researchers also plan to use the tool to study other mouse behaviors, learning and memory, and to examine how synapses change under certain conditions, such as aging, Alzheimer's Disease and autism. The research was supported by the National Institutes of Health's National Institute on Aging and National Institute of Mental Health (R21 AG063193, R01 MH123212, K99 MH124920) and a Schmidt Science Nascent Innovation Grant. Other scientists who contributed to the work are Richard Roth, Han Tan, Qianwen Zhu, Alexei Bygrave, Elena Lopez-Ortega, Ingie Hong, Alina Spiegel, Richard Johnson, Joshua Vogelstein, Daniel Tward and Michael Miller from Johns Hopkins. 