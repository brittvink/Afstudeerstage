For the first time, a team of researchers developed a method to experimentally evaluate how parents use what they know about their children's language when they talk to them. They found that parents have extremely precise models of their children's language knowledge, and use these models to tune the language they use when speaking to them. The results are available in an advance online publication of the journal of Psychological Science. We have known for years that parents talk to children differently than to other adults in a lot of ways, for example simplifying their speech, reduplicating words and stretching out vowel sounds," said Daniel Yurovsky, assistant professor in psychology at Carnegie Mellon University. "This stuff helps young kids get a toehold into language, but we didn't whether parents change the way they talk as children are acquiring language, giving children language input that is 'just right' for learning the next thing. Adults tend to speak to children more slowly and at a higher pitch. They also use more exaggerated enunciation, repetition and simplified language structure. Adults also pepper their communication with questions to gauge the child's comprehension. As the child's language fluency increases, the sentence structure and complexity used by adults increases. Yurovsky likens this to the progression a student follows when learning math in school. When you go to school, you start with algebra and then take plane geometry before moving onto calculus," said Yurovsky. "People talk to kids using same kind of structure without thinking about it. They are tracking how much their child knows about language and modifying how they speak so that for children understand them. Yurovsky and his team sought to understand exactly how caregivers tune their interactions to match their child's speech development. The team developed a game where parents helped their children to pick a specific animal from a set of three, a game that toddlers (aged 15 to 23 months) and their parents play routinely in their daily lives. Half of the animals in the matching game were animals that children typically learn before age 2 (e.g. cat, cow), and the other half were animals that are typically learned later (e.g. peacock, leopard). The researchers asked 41 child-adult pairs to play the game in a naturalistic setting in the laboratory. They measured the differences in how parents talked about animals they thought their children knew as compared to those they thought their children did not know. Parents have an incredibly precise knowledge of their child's language because they have witnessed them grow and learn," said Yurovsky. "These results show that parents leverage their knowledge of their children's language development to fine-tune the linguistic information they provide. The researchers found that the caregiver used a variety of techniques to convey the 'unknown' animal to the child. The most common approach was to use additional descriptors familiar to the child. This [research] approach lets us confirm experimentally ideas that we have developed based on observations of how children and parents engage in the home," said Yurovsky. "We found that parents not only used what they already knew about their children's language knowledge before the study, but also that if they found out they wrong -- their child didn't actually know 'leopard' for example -- they changed the way they talked about that animal the next time around. The study consisted of 36 experimental trials where each animal appeared as a target at least twice in the game. The participants represented a racial composition similar to the United States (56% white, 27% Black and 8% Hispanic). The results reflect a western parenting perspective as well as caregivers with a higher educational background than is representative in the country. The researchers did not independently measure the children's knowledge of each animal. The results of this study cannot differentiate whether the children learned any new animals while playing the game. Yurovsky believes the results may have some relevance for researchers working in the field of machine learning. These results could help us understand how to think about machine learning language systems," he said. "Right now we train language models by giving them all of the language data we can get our hands on all at once. But we might do better if we could give them the right data at the right time, keeping it at just the right level of complexity that they are ready for. Yurovsky was joined on this project by Ashley Leung at the University of Chicago and Alex Tunkel at The George Washington University School of Medicine and Health Sciences. This project received funds from the James S. McDonnell Foundation. 