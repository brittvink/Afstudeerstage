Deepfakes, a portmanteau of 'deep learning' and 'fake', are ultrarealistic fake videos made with artificial intelligence (AI) software to depict people doing things they have never done -- not just slowing them down or changing the pitch of their voice, but also making them appear to say things that they have never said at all. In a survey of 1,231 Singaporeans led by NTU Singapore's Assistant Professor Saifuddin Ahmed, 54 per cent of the respondents said they were aware of deepfakes, of which one in three reported sharing content on social media that they subsequently learnt was a deepfake. The study also found that more than one in five of those who are aware of deepfakes said that they regularly encounter deepfakes online. The survey findings, reported in the journal Telematics and Informatics in October, come in the wake of rising numbers of deepfake videos identified online. Over the six months to June 2020, Sensity, a deepfake detection technology firm , estimates that identified deepfake videos online had doubled to 49,081. Deepfakes that have gone viral include one with former President Barack Obama using an expletive to describe President Donald Trump in 2018, and another last year of Facebook founder Mark Zuckerberg claiming to control the future, thanks to stolen data. Assistant Professor Saifuddin of NTU's Wee Kim Wee School of Communication and Information said: "Fake news refers to false information published under the guise of being authentic news to mislead people, and deepfakes are a new, far more insidious form of fake news. In some countries, we are already witnessing how such deepfakes can be used to create non-consensual porn, incite fear and violence, and influence civic mistrust. As the AI technology behind the creation of deepfakes evolves, it will be even more challenging to discern fact from fiction. While tech companies like Facebook, Twitter and Google have started to label what they have identified as manipulated online content like deepfakes, more efforts will be required to educate the citizenry in effectively negating such content. Americans more likely than Singaporeans to share deepfakes The study benchmarked the findings on Singaporeans' understanding of deepfakes against a similar demographic and number of respondents in the United States. Respondents in the US were more aware of deepfakes (61% in US vs. 54% in SG). They said they were also more concerned by and frequently exposed to deepfakes. More people reported sharing content that they later learnt was a deepfake in the US than in Singapore (39% in US vs. 33% in SG). Asst Prof Saifuddin said: "These differences are not surprising, given the more widespread relevance and public discussion surrounding deepfakes in the US. More recently, a rise in the number of deepfakes, including those of President Donald Trump, has raised anxieties regarding the destructive potential of this form of disinformation. On the other hand, Singapore has not witnessed direct impacts of deepfakes, and the government has introduced the Protection from Online Falsehoods and Manipulation Act (POFMA) to limit the threat posed by disinformation, including deepfakes. But legislation alone is not enough, he added, citing a 2018 survey by global independent market research agency Ipsos which found that while four in five Singaporeans say that they can confidently spot fake news, more than 90 per cent mistakenly identified at least one in five fake headlines as being real. The government's legislation to inhibit the pervasive threat of disinformation has also been helpful, but we need to continue improving digital media literacy going forward, especially for those who are less capable of discerning facts from disinformation," said Asst Prof Saifuddin, whose research interests include social media and public opinion. The NTU study on deepfake awareness was funded by the University and Singapore's Ministry of Education, and the findings are part of a longer-term study that examines citizens' trust in AI technology. 